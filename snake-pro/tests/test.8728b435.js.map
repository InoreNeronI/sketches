{"mappings":"AAAA,MAAM,cAAc;IAClB,QAAQ;QACN,IAAI,KAAK;QACT,IAAI,KAAK;QACT,IAAI,OAAO,KAAK,IAAI,CAAC,IAAI,IAAI;QAC7B,IAAI,QAAQ;QACZ,IAAI,OAAO,KAAK,GAAG;QAEnB,IAAI,QAAQ,OAAO,KAAK,KAAK,GAAG,MAAM,MAAM,KAAK,KAAK,GAAG;QACzD,MAAM,MAAM,GAAG,MAAM,UAAU,CAAC,IAAI;QACpC,sBAAsB;QACtB,yDAAyD;QACzD,+BAA+B;QAC/B,GAAG,MAAM,MAAM,CAAC,MAAM,EAAE;QACxB,GAAG,MAAM,MAAM,CAAC,EAAE,CAAC,MAAM,EAAE;QAC3B,GAAG,MAAM,MAAM,CAAC,EAAE,CAAC,EAAE,CAAC,MAAM,EAAE,KAAK,UAAU,CAAC,MAAM;QACpD,GAAG,MAAM,MAAM,MAAM,CAAC,KAAK,GAAG;QAC9B,GAAG,MAAM,MAAM,SAAS,CAAC,MAAM;QAC/B,GAAG,MAAM,MAAM,SAAS,CAAC,MAAM;QAC/B,UAAU;QACV,GAAG,MAAM,MAAM,CAAC,EAAE,CAAC,EAAE,CAAC,MAAM,EAAE,KAAK,UAAU,CAAC,MAAM;QACpD,GAAG,MAAM,MAAM,MAAM,CAAC;QACtB,GAAG,MAAM,KAAK,KAAK,CAAC,EAAE,CAAC,MAAM,SAAS,CAAC;QACvC,GAAG,GAAG,MAAM,IAAI,CAAC;QACjB,WAAW;QACX,IAAI,QAAQ,MAAM,SAAS,CAAC,GAAG,CAAC,KAAK,KAAK;QAC1C,IAAI,QAAQ,MAAM,SAAS,CAAC,GAAG,CAAC,KAAK,KAAK;QAC1C,IAAI,OAAO,MAAM,SAAS,CAAC,GAAG,CAAC,KAAK,IAAI;QACxC,IAAI,OAAO,MAAM,SAAS,CAAC,GAAG,CAAC,KAAK,IAAI;QAExC,MAAM,IAAI,CAAC,OAAO,IAAI;QACtB,MAAM,IAAI,CAAC,OAAO,IAAI;QACtB,MAAM,IAAI,CAAC,MAAM,IAAI;QACrB,MAAM,IAAI,CAAC,MAAM,MAAM;QACvB,GAAG,OAAO,MAAM,MAAM,CAAC;QACvB,GAAG,MAAM,MAAM,SAAS,CAAC,MAAM;QAC/B,GAAG,OAAO,MAAM,SAAS,CAAC,MAAM;QAChC,IAAI,KAAK,MAAM,KAAK,CAAC;QAErB,GAAG,MAAM,EAAE,CAAC,MAAM,IAAI;QACtB,GAAG,MAAM,MAAM,IAAI,CAAC,OAAO,SAAS;QACpC,GAAG,MAAM,EAAE,CAAC,MAAM,IAAI;QACtB,GAAG,MAAM,MAAM,IAAI,CAAC,OAAO,SAAS;QACpC,GAAG,MAAM,EAAE,CAAC,KAAK,IAAI;QACrB,GAAG,MAAM,MAAM,IAAI,CAAC,MAAM,SAAS;QACnC,GAAG,MAAM,EAAE,CAAC,KAAK,IAAI;QACrB,GAAG,MAAM,MAAM,IAAI,CAAC,MAAM,SAAS;QACnC,GAAG,MAAM,KAAK,KAAK,CAAC,EAAE,CAAC,MAAM,SAAS,CAAC;QACvC,GAAG,IAAI,MAAM,IAAI,CAAC;QAElB,IAAK,IAAI,IAAI,GAAG,IAAI,IAAI,IAAK;YAC3B,MAAM,KAAK,MAAM,oBAAoB;YACrC,GACE,MACA,KAAK,UAAU,CAAC,IAAI,CAAC,CAAC,IAAM,EAAE,EAAE,CAAC,MAAM,SAAS,CAAC,GAAG,CAAC;QAEzD;IACF;AACF","sources":["src/snake-pro/tests/qLearn-tests.js"],"sourcesContent":["const QLearnTests = {\n  qlearn: () => {\n    let nx = 3;\n    let ny = 4;\n    let next = game.next(nx, ny, NodeSet());\n    let state = next();\n    let node = Node(1, 1);\n\n    let model = QLearn(300, 500, 1, 0.01, 0.05, 0.9, 0.9, 1, -1);\n    model.policy = model.initPolicy(nx, ny);\n    // This section checks\n    // initPolicy, getAction, getQs, getQ, setQ, allQEq, maxQ\n    // Policy Initialised correctly\n    eq(model.policy.length, nx);\n    eq(model.policy[0].length, ny);\n    eq(model.policy[1][2].length, game.DIRECTIONS.length);\n    eq(true, model.allQEq(Node(2, 3)));\n    eq(true, model.isExplore(node, 1));\n    eq(true, model.isExplore(node, 0));\n    // Initial\n    eq(model.policy[1][1].length, game.DIRECTIONS.length);\n    eq(true, model.allQEq(node));\n    eq(true, game.NORTH.eq(model.getAction(node)));\n    eq(0, model.maxQ(node));\n    // Modified\n    let north = model.actionMap.get(game.NORTH);\n    let south = model.actionMap.get(game.SOUTH);\n    let east = model.actionMap.get(game.EAST);\n    let west = model.actionMap.get(game.WEST);\n\n    model.setQ(north, -1, node);\n    model.setQ(south, 99, node);\n    model.setQ(east, 55, node);\n    model.setQ(west, -999, node);\n    eq(false, model.allQEq(node));\n    eq(true, model.isExplore(node, 1));\n    eq(false, model.isExplore(node, 0));\n    let qs = model.getQs(node);\n\n    eq(true, qs[north] == -1);\n    eq(true, model.getQ(north, node) == -1);\n    eq(true, qs[south] == 99);\n    eq(true, model.getQ(south, node) == 99);\n    eq(true, qs[east] == 55);\n    eq(true, model.getQ(east, node) == 55);\n    eq(true, qs[west] == -999);\n    eq(true, model.getQ(west, node) == -999);\n    eq(true, game.SOUTH.eq(model.getAction(node)));\n    eq(99, model.maxQ(node));\n\n    for (let i = 0; i < 10; i++) {\n      const ra = model.getRandomActionIndex();\n      eq(\n        true,\n        game.DIRECTIONS.some((n) => n.eq(model.actionMap.get(ra))),\n      );\n    }\n  },\n};\n"],"names":[],"version":3,"file":"test.8728b435.js.map"}